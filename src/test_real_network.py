"""
Test TRAF-GNN with Real LA Traffic Network Data
Tests model with 4,106 nodes from actual LA dataset
"""

import torch
import numpy as np
from pathlib import Path
import time
from model_mvgnn import create_model

print("=" * 70)
print("ðŸš¦ Testing TRAF-GNN with Real LA Traffic Network (4,106 nodes)")
print("=" * 70)

# Configuration
graphs_dir = Path('graphs')
batch_size = 4  # Smaller batch for large network
seq_length = 12
pred_horizon = 3
in_features = 1
hidden_dim = 64

# Load real graphs
print("\nðŸ“¥ Loading real LA traffic graphs...")
try:
    A_physical = np.load(graphs_dir / 'real_A_physical.npy')
    A_proximity = np.load(graphs_dir / 'real_A_proximity.npy')
    A_correlation = np.load(graphs_dir / 'real_A_correlation.npy')
    
    num_nodes = A_physical.shape[0]
    
    print(f"âœ“ Loaded graphs successfully")
    print(f"  Nodes: {num_nodes:,}")
    print(f"  Physical edges: {np.sum(A_physical > 0):,}")
    print(f"  Proximity edges: {np.sum(A_proximity > 0):,}")
    print(f"  Correlation edges: {np.sum(A_correlation > 0):,}")
    
    graphs = {
        'physical': torch.FloatTensor(A_physical),
        'proximity': torch.FloatTensor(A_proximity),
        'correlation': torch.FloatTensor(A_correlation)
    }
    
except FileNotFoundError:
    print("âš ï¸  Real graphs not found! Using demo graphs (207 nodes) instead...")
    num_nodes = 207
    adj = np.eye(num_nodes, dtype=np.float32)
    graphs = {
        'physical': torch.FloatTensor(adj),
        'proximity': torch.FloatTensor(adj),
        'correlation': torch.FloatTensor(adj)
    }

# Create model for real network
print(f"\nðŸ—ï¸  Creating TRAF-GNN model for {num_nodes:,} nodes...")
model = create_model(
    num_nodes=num_nodes,
    config={
        'in_features': in_features,
        'hidden_dim': hidden_dim,
        'num_gnn_layers': 2,
        'num_temporal_layers': 2,
        'pred_horizon': pred_horizon,
        'dropout': 0.3
    }
)

print(f"âœ“ Model created")
print(f"  Total parameters: {model.count_parameters():,}")

# Calculate model memory
param_memory = model.count_parameters() * 4 / (1024 * 1024)  # MB
print(f"  Parameter memory: {param_memory:.2f} MB")

# Create dummy input data (simulating real traffic data)
print(f"\nðŸ“Š Creating test input...")
print(f"  Batch size: {batch_size}")
print(f"  Sequence length: {seq_length}")
print(f"  Nodes: {num_nodes:,}")
print(f"  Features: {in_features}")

x = torch.randn(batch_size, seq_length, num_nodes, in_features)

input_memory = x.numel() * 4 / (1024 * 1024)  # MB
print(f"âœ“ Input created")
print(f"  Shape: {tuple(x.shape)}")
print(f"  Memory: {input_memory:.2f} MB")

# Test forward pass
print(f"\nðŸ§ª Running forward pass...")
print(f"  (This may take a moment for {num_nodes:,} nodes...)")

model.eval()
start_time = time.time()

with torch.no_grad():
    try:
        output = model(x, graphs)
        inference_time = time.time() - start_time
        
        print(f"âœ… Forward pass successful!")
        print(f"  Time: {inference_time:.2f} seconds")
        print(f"  Speed: {inference_time/batch_size:.3f} sec/sample")
        print(f"\n  Output shape: {tuple(output.shape)}")
        print(f"  Expected: ({batch_size}, {pred_horizon}, {num_nodes}, {in_features})")
        
        # Verify shape
        expected_shape = (batch_size, pred_horizon, num_nodes, in_features)
        assert output.shape == expected_shape, f"Shape mismatch! Got {output.shape}, expected {expected_shape}"
        
        # Check for NaN or Inf
        if torch.isnan(output).any():
            print("  âš ï¸  Warning: Output contains NaN values")
        elif torch.isinf(output).any():
            print("  âš ï¸  Warning: Output contains Inf values")
        else:
            print("  âœ“ Output is valid (no NaN/Inf)")
        
        # Output statistics
        print(f"\nðŸ“ˆ Output Statistics:")
        print(f"  Mean: {output.mean().item():.4f}")
        print(f"  Std: {output.std().item():.4f}")
        print(f"  Min: {output.min().item():.4f}")
        print(f"  Max: {output.max().item():.4f}")
        
    except Exception as e:
        print(f"âŒ Forward pass failed: {e}")
        import traceback
        traceback.print_exc()

# Memory usage summary
print(f"\nðŸ’¾ Memory Usage Summary:")
print(f"  Model parameters: {param_memory:.2f} MB")
print(f"  Input batch: {input_memory:.2f} MB")
print(f"  Graphs (3 Ã— {num_nodes}Â²): {3 * num_nodes * num_nodes * 4 / (1024 * 1024):.2f} MB")

total_memory = param_memory + input_memory + (3 * num_nodes * num_nodes * 4 / (1024 * 1024))
print(f"  Estimated total: {total_memory:.2f} MB")

# Performance analysis
print(f"\nâš¡ Performance Analysis:")
if num_nodes >= 1000:
    print(f"  Network scale: LARGE ({num_nodes:,} nodes)")
    print(f"  Suitable for: Full city-wide traffic forecasting")
else:
    print(f"  Network scale: MEDIUM ({num_nodes:,} nodes)")
    print(f"  Suitable for: District-level forecasting")

if inference_time < 1.0:
    print(f"  Speed: FAST (<1 second per batch)")
elif inference_time < 5.0:
    print(f"  Speed: GOOD (1-5 seconds per batch)")
else:
    print(f"  Speed: SLOW (>5 seconds per batch)")
    print(f"  Consider: Smaller batch size or model pruning")

print(f"\n" + "=" * 70)
print("âœ… Real Network Test Complete!")
print("=" * 70)

print(f"\nðŸŽ¯ Summary:")
print(f"  âœ“ Model handles {num_nodes:,} nodes successfully")
print(f"  âœ“ Forward pass works correctly")
print(f"  âœ“ Output shape is correct")
print(f"  âœ“ Ready for training on real LA traffic data!")
print(f"\nðŸ’¡ Note: With {num_nodes:,} nodes, training will be {num_nodes/207:.1f}x slower")
print(f"   than the 207-node demo. Consider using demo graphs for")
print(f"   quick experimentation, then scale up for final training.")
print("=" * 70)
