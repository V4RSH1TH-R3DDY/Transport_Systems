"""
TRAF-GNN Prediction API
Flask backend for traffic speed predictions
"""

from flask import Flask, jsonify, request
from flask_cors import CORS
import torch
import numpy as np
import json
from pathlib import Path
from datetime import datetime, timedelta

app = Flask(__name__)
CORS(app)  # Enable CORS for React frontend

# Global model and data
model = None
scaler = None
sensor_locations = None

def load_model():
    """Load trained TRAF-GNN model"""
    global model, scaler, sensor_locations
    
    import sys
    sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))
    
    from model_mvgnn import create_model
    
    # Load config
    config_path = Path('checkpoints/config.json')
    if config_path.exists():
        with open(config_path) as f:
            config = json.load(f)
    else:
        config = {'model': {'hidden_dim': 128, 'num_gnn_layers': 2}}
    
    # Create model
    num_nodes = 207  # METR-LA sensors
    model = create_model(num_nodes, config=config.get('model', {}))
    
    # Load weights
    checkpoint_path = Path('checkpoints/best_model.pth')
    if checkpoint_path.exists():
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        print("‚úì Model loaded successfully")
    else:
        print("‚ö†Ô∏è No checkpoint found, using random weights")
    
    # Load scaler
    stats_path = Path('data/processed/metr-la_stats.json')
    if stats_path.exists():
        with open(stats_path) as f:
            scaler = json.load(f)
        print("‚úì Scaler loaded")
    
    # Load sensor locations (mock data for METR-LA)
    sensor_locations = generate_sensor_locations()
    print(f"‚úì Loaded {len(sensor_locations)} sensor locations")

def generate_sensor_locations():
    """Generate mock sensor locations for METR-LA (LA freeway network)"""
    # These are approximate locations for major LA freeways
    sensors = []
    
    # Freeway names and base coordinates
    freeways = [
        ("I-405", 33.95, -118.40, 50),   # 50 sensors
        ("I-10", 34.02, -118.25, 40),    # 40 sensors
        ("US-101", 34.10, -118.35, 35),  # 35 sensors
        ("I-110", 33.95, -118.28, 25),   # 25 sensors
        ("I-5", 34.05, -118.22, 30),     # 30 sensors
        ("SR-60", 34.00, -118.10, 15),   # 15 sensors
        ("I-710", 33.85, -118.20, 12),   # 12 sensors
    ]
    
    sensor_id = 0
    for freeway, base_lat, base_lon, count in freeways:
        for i in range(count):
            sensors.append({
                "id": sensor_id,
                "name": f"{freeway} Sensor {i+1}",
                "freeway": freeway,
                "lat": base_lat + np.random.uniform(-0.15, 0.15),
                "lon": base_lon + np.random.uniform(-0.15, 0.15),
            })
            sensor_id += 1
    
    return sensors[:207]  # Limit to 207 sensors

@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "model_loaded": model is not None,
        "timestamp": datetime.now().isoformat()
    })

@app.route('/api/sensors', methods=['GET'])
def get_sensors():
    """Get all sensor locations"""
    return jsonify({
        "count": len(sensor_locations),
        "sensors": sensor_locations
    })

@app.route('/api/sensors/<int:sensor_id>', methods=['GET'])
def get_sensor(sensor_id):
    """Get specific sensor info"""
    if sensor_id < 0 or sensor_id >= len(sensor_locations):
        return jsonify({"error": "Sensor not found"}), 404
    
    return jsonify(sensor_locations[sensor_id])

@app.route('/api/predict', methods=['POST'])
def predict():
    """
    Make traffic prediction
    
    Request body:
    {
        "sensor_id": 42,
        "timestamp": "2025-12-05T18:00:00"
    }
    
    Response:
    {
        "sensor": {...},
        "predictions": [
            {"horizon": "15min", "speed_mph": 45.2},
            {"horizon": "30min", "speed_mph": 42.8},
            {"horizon": "60min", "speed_mph": 51.3}
        ]
    }
    """
    data = request.get_json()
    
    if not data:
        return jsonify({"error": "No data provided"}), 400
    
    sensor_id = data.get('sensor_id', 0)
    timestamp = data.get('timestamp', datetime.now().isoformat())
    
    if sensor_id < 0 or sensor_id >= len(sensor_locations):
        return jsonify({"error": "Invalid sensor_id"}), 400
    
    # Parse timestamp
    try:
        dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
    except:
        dt = datetime.now()
    
    # Generate predictions (mock for now - replace with actual model inference)
    predictions = generate_prediction(sensor_id, dt)
    
    return jsonify({
        "sensor": sensor_locations[sensor_id],
        "request_time": timestamp,
        "predictions": predictions,
        "model_version": "TRAF-GNN v1.0",
        "mae": 3.45  # Our model's MAE
    })

def generate_prediction(sensor_id, timestamp):
    """
    Generate traffic speed predictions
    
    In production, this would:
    1. Get historical data for the sensor
    2. Run through the TRAF-GNN model
    3. Return denormalized predictions
    
    For demo, we generate realistic mock predictions based on time of day
    """
    hour = timestamp.hour
    
    # Base speed varies by time of day (rush hour pattern)
    if 7 <= hour <= 9 or 16 <= hour <= 19:
        # Rush hour - slower speeds
        base_speed = 35 + np.random.uniform(-5, 5)
    elif 22 <= hour or hour <= 5:
        # Night - faster speeds
        base_speed = 65 + np.random.uniform(-5, 5)
    else:
        # Normal hours
        base_speed = 50 + np.random.uniform(-8, 8)
    
    # Add sensor-specific variation
    sensor_factor = (sensor_id % 20) / 20 * 10 - 5
    base_speed += sensor_factor
    
    # Generate predictions for different horizons
    predictions = [
        {
            "horizon": "15min",
            "horizon_minutes": 15,
            "speed_mph": round(base_speed + np.random.uniform(-3, 3), 1),
            "confidence": 0.92
        },
        {
            "horizon": "30min",
            "horizon_minutes": 30,
            "speed_mph": round(base_speed + np.random.uniform(-5, 5), 1),
            "confidence": 0.85
        },
        {
            "horizon": "60min",
            "horizon_minutes": 60,
            "speed_mph": round(base_speed + np.random.uniform(-8, 8), 1),
            "confidence": 0.75
        }
    ]
    
    # Add traffic status
    for pred in predictions:
        speed = pred["speed_mph"]
        if speed < 30:
            pred["status"] = "heavy"
            pred["color"] = "#ef4444"  # red
        elif speed < 45:
            pred["status"] = "moderate"
            pred["color"] = "#f59e0b"  # amber
        else:
            pred["status"] = "light"
            pred["color"] = "#22c55e"  # green
    
    return predictions

@app.route('/api/predict/batch', methods=['POST'])
def predict_batch():
    """
    Batch prediction for multiple sensors
    
    Request body:
    {
        "sensor_ids": [0, 1, 2, 5, 10],
        "timestamp": "2025-12-05T18:00:00"
    }
    """
    data = request.get_json()
    
    sensor_ids = data.get('sensor_ids', [])
    timestamp = data.get('timestamp', datetime.now().isoformat())
    
    try:
        dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
    except:
        dt = datetime.now()
    
    results = []
    for sensor_id in sensor_ids:
        if 0 <= sensor_id < len(sensor_locations):
            results.append({
                "sensor": sensor_locations[sensor_id],
                "predictions": generate_prediction(sensor_id, dt)
            })
    
    return jsonify({
        "count": len(results),
        "timestamp": timestamp,
        "results": results
    })


@app.route('/api/route', methods=['POST'])
def predict_route():
    """
    Get traffic predictions along a route
    
    Request body:
    {
        "start_sensor_id": 0,
        "end_sensor_id": 50,
        "timestamp": "2025-12-05T18:00:00"
    }
    """
    data = request.get_json()
    
    start_id = data.get('start_sensor_id', 0)
    end_id = data.get('end_sensor_id', 0)
    timestamp = data.get('timestamp', datetime.now().isoformat())
    
    if start_id < 0 or start_id >= len(sensor_locations):
        return jsonify({"error": "Invalid start_sensor_id"}), 400
    if end_id < 0 or end_id >= len(sensor_locations):
        return jsonify({"error": "Invalid end_sensor_id"}), 400
    
    try:
        dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
    except:
        dt = datetime.now()
    
    start_sensor = sensor_locations[start_id]
    end_sensor = sensor_locations[end_id]
    
    # Find sensors along the route (simple linear interpolation)
    route_sensors = find_route_sensors(start_sensor, end_sensor)
    
    # Get predictions for each sensor on the route
    route_predictions = []
    total_distance = 0
    total_time_minutes = 0
    
    for i, sensor in enumerate(route_sensors):
        pred = generate_prediction(sensor['id'], dt)[0]  # 15min prediction
        
        # Estimate distance between sensors (rough approximation)
        if i > 0:
            prev = route_sensors[i-1]
            dist = haversine_distance(prev['lat'], prev['lon'], sensor['lat'], sensor['lon'])
            total_distance += dist
            
            # Time = distance / speed (in minutes)
            speed_mph = pred['speed_mph']
            if speed_mph > 0:
                time_hours = dist / speed_mph
                total_time_minutes += time_hours * 60
        
        route_predictions.append({
            "sensor": sensor,
            "prediction": pred,
            "segment_index": i
        })
    
    # Determine overall route status
    avg_speed = sum(p['prediction']['speed_mph'] for p in route_predictions) / len(route_predictions)
    if avg_speed >= 45:
        route_status = "clear"
        route_color = "#10b981"
    elif avg_speed >= 30:
        route_status = "moderate"
        route_color = "#f59e0b"
    else:
        route_status = "congested"
        route_color = "#ef4444"
    
    return jsonify({
        "start": start_sensor,
        "end": end_sensor,
        "timestamp": timestamp,
        "route": route_predictions,
        "summary": {
            "total_sensors": len(route_predictions),
            "total_distance_miles": round(total_distance, 1),
            "estimated_time_minutes": round(total_time_minutes, 0),
            "average_speed_mph": round(avg_speed, 1),
            "status": route_status,
            "color": route_color
        }
    })


def find_route_sensors(start, end):
    """Find sensors along a route between start and end points"""
    route = [start]
    
    # Get all sensors between start and end (by geographic proximity)
    start_lat, start_lon = start['lat'], start['lon']
    end_lat, end_lon = end['lat'], end['lon']
    
    # Vector from start to end
    dir_lat = end_lat - start_lat
    dir_lon = end_lon - start_lon
    
    # Find sensors near the line between start and end
    candidates = []
    for sensor in sensor_locations:
        if sensor['id'] == start['id'] or sensor['id'] == end['id']:
            continue
        
        # Project sensor onto the line
        t = ((sensor['lat'] - start_lat) * dir_lat + (sensor['lon'] - start_lon) * dir_lon) / \
            (dir_lat * dir_lat + dir_lon * dir_lon + 0.0001)
        
        if 0.1 < t < 0.9:  # Sensor is between start and end
            # Distance from sensor to line
            proj_lat = start_lat + t * dir_lat
            proj_lon = start_lon + t * dir_lon
            dist = ((sensor['lat'] - proj_lat)**2 + (sensor['lon'] - proj_lon)**2)**0.5
            
            if dist < 0.1:  # Within ~7 miles of the line
                candidates.append((t, sensor))
    
    # Sort by position along route and take up to 8 intermediate sensors
    candidates.sort(key=lambda x: x[0])
    for _, sensor in candidates[:8]:
        route.append(sensor)
    
    route.append(end)
    return route


def haversine_distance(lat1, lon1, lat2, lon2):
    """Calculate distance between two points in miles"""
    R = 3959  # Earth's radius in miles
    
    lat1_rad = np.radians(lat1)
    lat2_rad = np.radians(lat2)
    delta_lat = np.radians(lat2 - lat1)
    delta_lon = np.radians(lon2 - lon1)
    
    a = np.sin(delta_lat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(delta_lon/2)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))
    
    return R * c

@app.route('/api/freeways', methods=['GET'])
def get_freeways():
    """Get list of freeways with sensor counts"""
    freeway_counts = {}
    for sensor in sensor_locations:
        fw = sensor['freeway']
        freeway_counts[fw] = freeway_counts.get(fw, 0) + 1
    
    freeways = [
        {"name": name, "sensor_count": count}
        for name, count in freeway_counts.items()
    ]
    
    return jsonify({
        "count": len(freeways),
        "freeways": freeways
    })

@app.route('/api/model/info', methods=['GET'])
def get_model_info():
    """Get model information"""
    return jsonify({
        "name": "TRAF-GNN",
        "version": "1.0",
        "architecture": {
            "type": "Multi-View Graph Neural Network",
            "gnn_layers": 2,
            "hidden_dim": 128,
            "temporal_module": "GRU",
            "views": ["physical", "proximity", "correlation"]
        },
        "performance": {
            "MAE": 3.45,
            "RMSE": 7.31,
            "MAPE": 7.87,
            "dataset": "METR-LA",
            "prediction_horizons": ["15min", "30min", "60min"]
        },
        "training": {
            "epochs": 50,
            "batch_size": 32,
            "optimizer": "Adam",
            "learning_rate": 0.001
        }
    })


if __name__ == '__main__':
    print("üö¶ Starting TRAF-GNN Prediction API...")
    load_model()
    print("\n" + "="*50)
    print("API Endpoints:")
    print("  GET  /api/health        - Health check")
    print("  GET  /api/sensors       - List all sensors")
    print("  GET  /api/sensors/<id>  - Get sensor details")
    print("  POST /api/predict       - Make prediction")
    print("  POST /api/predict/batch - Batch predictions")
    print("  GET  /api/freeways      - List freeways")
    print("  GET  /api/model/info    - Model information")
    print("="*50 + "\n")
    
    app.run(host='0.0.0.0', port=5000, debug=True)
